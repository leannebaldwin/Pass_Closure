{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load ../src/weather_data_clean.py\n",
    "import pandas as pd\n",
    "\n",
    "def clean_weather_data(filename):\n",
    "    \"\"\"Take ASOS weather data file for Stampede pass and clean it ready for input to model.\n",
    "    Input: txt file\n",
    "    Output: pandas dataframe\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(filename)\n",
    "\n",
    "    # Rename two of the columns\n",
    "    data.rename(columns={'valid':'date', 'tmpf':'temp'}, inplace=True)\n",
    "\n",
    "    # Remove the few rows that have a null value for temp\n",
    "    data = data[~data.temp.eq('M')]\n",
    "\n",
    "    # Remove spaces from column names\n",
    "    data.rename(columns=lambda x: x.replace(' ', ''), inplace=True)\n",
    "\n",
    "    # Only use the standard hourly weather reading at 56 mins past each hour\n",
    "    mask = data['date'].apply(lambda x: x[-2:] == '56')\n",
    "    data = data[mask]\n",
    "\n",
    "    # Create a date series to be used in the clean dataframe\n",
    "    date = pd.to_datetime(data['date'])\n",
    "\n",
    "    # Create a temp series to be used in the clean dataframe\n",
    "    temp = data['temp'].apply(float)\n",
    "\n",
    "    # Cast the null value M to zero to enable create of the raw precipitation series cast to floats\n",
    "    data.p01i[data.p01i == 'M'] = 0\n",
    "    raw_precipitation = data['p01i'].apply(float)\n",
    "\n",
    "    # Create a precipitation series to be used in the clean dataframe\n",
    "    precipitation = raw_precipitation.apply(lambda x: True if (x > 0) else False)\n",
    "\n",
    "    # Convert sky coverage data to clear or cloudy and create an overcast series to be used in the clean dataframe\n",
    "    sky_elements = ['skyc1', 'skyc2', 'skyc3']\n",
    "    data.skyc1 = data.skyc1.astype(str)\n",
    "    data.skyc2 = data.skyc2.astype(str)\n",
    "    data.skyc3 = data.skyc3.astype(str)\n",
    "    sky_agg = data[sky_elements].values.tolist()\n",
    "    sky_reduce = [['overcast' if (('BKN' in element) or ('OVC' in element) or ('VV' in element)) else 'clear'\n",
    "                    for element in row] for row in sky_agg]\n",
    "    overcast = pd.Series([True if 'overcast' in row else False for row in sky_reduce])\n",
    "    overcast.index = date.index\n",
    "\n",
    "    # Cast the null value 'M' to 10.00 to enable the creation of a poor visibility series\n",
    "    data.vsby[data.vsby == 'M'] = 10.00\n",
    "    raw_visibility = data['vsby'].apply(float)\n",
    "    poor_visibility = pd.Series([True if value < 0.50 else False for value in raw_visibility])\n",
    "    poor_visibility.index = date.index\n",
    "\n",
    "    # Cast the null value 'M' to 0 to enable the creation of a windy series\n",
    "    data.sknt[data.sknt == 'M'] = 0.00\n",
    "    data.gust[data.gust == 'M'] = 0.00\n",
    "    wind_speed = data['sknt'].apply(float)\n",
    "    gust_speed = data['gust'].apply(float)\n",
    "    wind_df = pd.concat([wind_speed, gust_speed], axis=1)\n",
    "    # Finally apply the function f to enable the creation of the windy column\n",
    "    windy = wind_df.apply(f, axis=1)\n",
    "\n",
    "    \"\"\"Create the cleaned dataframe by concatenating the date, temp, precipitation, overcast, poor_visibility\n",
    "    and windy series\"\"\"\n",
    "    df = pd.concat([date, temp, precipitation, overcast, poor_visibility, windy], axis=1)\n",
    "    df.columns = ['date', 'temp', 'precipitation', 'overcast', 'poor_visibility', 'windy']\n",
    "    cleaned_df = df[(df['date'] > '2006-12-31') & (df['date'] < '2018-04-03')]\n",
    "    return cleaned_df\n",
    "\n",
    "def f(row):\n",
    "    \"\"\"Function to be able to create the windy series with windy being true if wind speed is above 10 knots\n",
    "    or gust speed is above 20 knots\"\"\"\n",
    "    if row['sknt'] >= 10.00:\n",
    "        val = True\n",
    "    elif row['gust'] >= 20.00:\n",
    "        val = True\n",
    "    else:\n",
    "        val = False\n",
    "    return val\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leanne/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2802: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "weather_df = clean_weather_data('ASOS_stampede_pass/SMP-2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load ../src/pass_data_clean.py\n",
    "import pandas as pd\n",
    "\n",
    "def clean_pass_data(filename):\n",
    "    \"\"\"Take Snoqualmie pass closure data file and clean it ready for input to model.\n",
    "    Input: xlsx file\n",
    "    Output: Pandas dataframe\n",
    "    \"\"\"\n",
    "    data = pd.read_excel(filename, header=[1])\n",
    "\n",
    "    #drop unnamed/unnecessary columns\n",
    "    data.drop(data.columns[[11,12,13,14]], axis=1, inplace=True)\n",
    "\n",
    "    #drop unnecessary secondary incident columns\n",
    "    data.drop(data.columns[[1,8]], axis=1, inplace=True)\n",
    "\n",
    "    #rename 'Incident...' columns to start_time and end_time \n",
    "    data.rename(columns={'INCIDENT START TIMES FOR EACH DIRECTION':'start_time'}, inplace=True)\n",
    "    data.rename(columns={'INCIDENT END TIMES - DIRECTIONAL':'end_time'}, inplace=True)\n",
    "\n",
    "    #use only dates from 2007-01-01 to match with available weather and traffic volume data\n",
    "    df = data[(data['start_time'] > '2006-12-31')]\n",
    "\n",
    "    #rename 'Delay Time Total' to delay\n",
    "    df.rename(columns={'Delay Time Total':'delay'}, inplace=True)\n",
    "\n",
    "    #drop row with nan value in delay\n",
    "    df = df.dropna(subset=['delay'])\n",
    "\n",
    "    #create a westbound pandas series with True if westbound and false if eastbound\n",
    "    westbound = pd.Series([True if value == 'WB' else False for value in df.DIRECTION])\n",
    "\n",
    "    #create a snow pandas series with True if weather description contains sn, false otherwise\n",
    "    snow = df.WEATHER.str.contains('sn', case=False, na=False, regex=True)\n",
    "\n",
    "    #create pandas series for start and end times\n",
    "    start_time = pd.to_datetime(df['start_time'])\n",
    "    end_time = pd.to_datetime(df['end_time'])\n",
    "\n",
    "    #ensure that all the pandas series created have the same index\n",
    "    westbound.index = start_time.index\n",
    "    snow.index = start_time.index\n",
    "    end_time.index = start_time.index\n",
    "\n",
    "    #create cleaned df with the series created\n",
    "    cleaned_df = pd.concat([start_time, end_time, westbound, snow], axis=1)\n",
    "\n",
    "    #rename columns\n",
    "    cleaned_df.rename(columns={0:'westbound', 'WEATHER':'snow'}, inplace=True)\n",
    "\n",
    "    return cleaned_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leanne/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:3781: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  return super(DataFrame, self).rename(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# %load ../src/combine_data.py\n",
    "\n",
    "pass_closure_df = clean_pass_data('Cumulative_Snoqualmie_Pass_Delay_Closures_1992_2018.xlsx')\n",
    "\n",
    "def get_pass_closure(date_time):\n",
    "    \"\"\"take a date_time and check if it is between the start and end times of a closure event\n",
    "    input: datetime\n",
    "    output: boolean\n",
    "    \"\"\"\n",
    "    start_end_times = list(zip(pass_closure_df.start_time, pass_closure_df.end_time))\n",
    "    for row in start_end_times:\n",
    "        if row[0] <= date_time <= row[1]:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def add_pass_closed(df):\n",
    "    \"\"\"take the weather df and add a new column for whether or not the pass is closed at each date_time\n",
    "    input: pandas dataframe\n",
    "    output: pandas dataframe\n",
    "    \"\"\"\n",
    "    df['pass_closed'] = df['date'].map(get_pass_closure)\n",
    "    return df\n",
    "\n",
    "def aggregate_data_to_daily(df):\n",
    "    \"\"\"take the combined df and aggregate the data into daily rather than hourly data to be used to train the model\n",
    "    input: pandas dataframe\n",
    "    output: pandas dataframe\n",
    "    \"\"\"\n",
    "    daily_df = df.resample(\"D\").agg({'temp':'mean','precipitation':'max', 'overcast':'max', 'poor_visibility':'max', 'windy':'max', 'pass_closed':'max'})\n",
    "    daily_df.dropna(inplace=True)\n",
    "    return daily_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_df = add_pass_closed(weather_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
